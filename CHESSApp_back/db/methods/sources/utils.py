from typing import Dict, List, Optional, Tuple
import os
from db.methods.TX import TX

def organize_all_source_versions(source_versions_data):
    """
    Converts the flat list from get_all_source_versions() into a nested structure:
    {
        source_id: {
            "source_id": source_id,
            "name": source_name,
            "information": source_information,
            "link": source_link,
            "citation": source_citation,
            "last_updated": source_last_updated,
            "versions": {
                sv_id: {
                    "sv_id": sv_id,
                    "version_name": version_name,
                    "version_rank": version_rank,
                    "last_updated": last_updated,
                    "assemblies": {
                        sva_id: {
                            "sva_id": sva_id,   
                            "assembly_id": assembly_id,
                            "files": {
                                file_key: {
                                    "file_path": file_path,
                                    "nomenclature": nomenclature,
                                    "filetype": file_type,
                                    "file_description": file_description
                                }
                            }
                        }
                    }
                }
            }
    }
    """
    sources_dict = {}
    for source in source_versions_data:
        source_id = source['source_id']
        sv_id = source['sv_id']
        sva_id = source.get('sva_id')
        
        if source_id not in sources_dict:
            sources_dict[source_id] = {
                "source_id": source_id,
                "name": source['source_name'],
                "information": source['information'],
                "link": source['link'],
                "citation": source['citation'],
                "last_updated": source['last_updated'],
                "versions": {}
            }
        
        if sv_id not in sources_dict[source_id]["versions"]:
            sources_dict[source_id]["versions"][sv_id] = {
                "sv_id": sv_id,
                "version_name": source['version_name'],
                "version_rank": source['version_rank'],
                "last_updated": source['last_updated'],
                "assemblies": {}
            }
        
        if sva_id:
            if sva_id not in sources_dict[source_id]["versions"][sv_id]["assemblies"]:
                sources_dict[source_id]["versions"][sv_id]["assemblies"][sva_id] = {
                    "sva_id": sva_id,
                    "assembly_id": source.get('assembly_id'),
                    "files": {},
                    # Add feature types here
                    "gene_types": source.get('gene_types', []),
                    "transcript_types": source.get('transcript_types', [])
                }
            
            file_path = source.get('file_path')
            if file_path:
                # Use a combination of nomenclature and file type as key
                nomenclature = source.get('nomenclature', 'unknown')
                file_type = source.get('filetype', 'unknown')
                file_key = f"{nomenclature}_{file_type}"
                
                sources_dict[source_id]["versions"][sv_id]["assemblies"][sva_id]["files"][file_key] = {
                    "file_path": file_path,
                    "nomenclature": nomenclature,
                    "filetype": file_type,
                    "file_description": source.get('file_description')
                }

    return sources_dict

def group_rows(rows: List[Dict]) -> TX:
    """
    Group database rows by transcript ID and yield TX objects.
    
    Args:
        rows: List of dictionaries containing transcript and intron data
    
    Yields:
        TX: Transcript objects with populated exon information
    """
    tx = TX()
    
    for row in rows:
        tid = row['tid']  # transcript ID
        
        if tx.tid != tid:
            if tx.tid is not None:
                tx.exons_from_introns()
                yield tx
            tx = TX()
        
        # Populate transcript data from row
        tx.tid = tid
        tx.strand = "+" if row['strand'] == 1 else "-"
        tx.seqid = row['sequence_name']
        tx.start = int(row['start'])
        tx.end = int(row['end'])
        tx.introns.append((int(row['intron_start']), int(row['intron_end'])))
    
    # Don't forget to yield the last transcript
    if tx.tid is not None:
        tx.exons_from_introns()
        yield tx

# parses the .tracking file generated by gffcompare and builds a map of reference to query transcripts
# this is used inplace of simply parsing the annotated.gtf and relying on the class_code field, since gffcompare removes all non-essential attributes
def load_tracking(tracking_fname:str) -> dict:
    assert os.path.exists(tracking_fname),"tracking file does not exist: "+tracking_fname
    res = dict()
    with open(tracking_fname, 'r') as trackingFP:
        for line in trackingFP:
            lcs = line.strip().split("\t")
            assert len(lcs)==5,"Invalid line in the tracking file: "+line
            if lcs[3] == "=":
                ref_tid = lcs[2].split("|")[1]
                qry_tid = lcs[4].split("|")[1]
                res[qry_tid] = ref_tid
    return res

def organize_feature_types(feature_types_data):
    """
    Organize feature types (genes or transcripts) by sva_id.
    Returns: {sva_id: [list of type_values]}
    """
    types_by_sva = {}
    for row in feature_types_data:
        sva_id = row.sva_id
        type_value = row.type_value
        
        if sva_id not in types_by_sva:
            types_by_sva[sva_id] = set()
        
        types_by_sva[sva_id].add(type_value)
    
    # Convert sets to sorted lists for JSON serialization
    for sva_id in types_by_sva:
        types_by_sva[sva_id] = sorted(list(types_by_sva[sva_id]))
    
    return types_by_sva