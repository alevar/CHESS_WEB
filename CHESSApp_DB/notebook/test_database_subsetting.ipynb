{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import argparse\n",
    "import subprocess\n",
    "\n",
    "import mysql.connector\n",
    "\n",
    "from itertools import chain, combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from definitions import *\n",
    "import api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MySQL database\n"
     ]
    }
   ],
   "source": [
    "CHESSDB_HOST = \"localhost\"\n",
    "CHESSDB_USER = \"chess_master\"\n",
    "CHESSDB_PASSWORD = \"qwerty\"\n",
    "CHESSDB_PORT = \"3306\"\n",
    "CHESSDB_NAME = \"CHESS_DB\"\n",
    "\n",
    "chessApi = None\n",
    "try:\n",
    "    chessApi = api.CHESS_DB_API(CHESSDB_HOST, CHESSDB_USER, CHESSDB_PASSWORD, CHESSDB_NAME, CHESSDB_PORT)\n",
    "    chessApi.connect()\n",
    "except:\n",
    "    print(\"Failed to connect to database\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Functionality Under Test\n",
    "####################\n",
    "\n",
    "\n",
    "\"\"\"\"\n",
    "*** Data from all sources are being: ordered by tid --> ordered by attribute name --> then order by priority listed in the data_sources list.\n",
    "*** The first row for each attribute name in each tid grouping is selected as the row to keep\n",
    "\n",
    "Hypothesis:\n",
    "I don't believe the SQL query accounts for cases where there is an attribute in a rank that is not 1, and this attribute is not in the others\n",
    "This line needs to be changed:  WHERE rn = 1 AND (source_name = 'CHESS.3.0' OR source_name = 'RefSeq' OR source_name = 'MANE')\n",
    "\n",
    "***Update: I was wrong. The query does account for this. The query is selecting the first row for each attribute name in each attribute grouping.\n",
    "\n",
    "\n",
    "Database to create for testing:\n",
    "- Should contain data from three sources: MANE, RefSeq, and CHESS.3.0\n",
    "- Should contain attributes that are in all three sources, and attributes that are in only one or two sources\n",
    "\n",
    "Questions:\n",
    "- Are SQL queries I run on the database making permanent changes to the database? (e.g. if I DELETE a table, will it be gone in subsequent tests?)\n",
    "\"\"\"\n",
    "\n",
    "# sourceId\n",
    "# 1 --> MANE, 2 --> RefSeq, 3 --> GENCODE, 4 --> CHESS.3.0\n",
    "\n",
    "# Attributes in source 1 and 2\n",
    "common_attr_name_two_sources = '''SELECT COUNT(DISTINCT name)\n",
    "FROM Attributes\n",
    "WHERE sourceId = '1'\n",
    "AND name IN (SELECT DISTINCT name FROM Attributes WHERE sourceId = '2')\n",
    "'''\n",
    "# Attributes in MANE\n",
    "single_source_attr_names_MANE= '''SELECT DISTINCT name FROM Attributes WHERE sourceId = '1' '''\n",
    "# Attributes in GENCODE\n",
    "single_source_attr_names_GENCODE= '''SELECT DISTINCT name FROM Attributes WHERE sourceId = '3' '''\n",
    "\n",
    "\n",
    "# Attributes in source 1 but not 2 \n",
    "diff_attr_name_two_sources = '''SELECT DISTINCT A1.name\n",
    "FROM Attributes A1\n",
    "LEFT JOIN Attributes A2 ON A1.name = A2.name AND A2.sourceId = '4'\n",
    "WHERE A1.sourceId = '2' AND A2.name IS NULL'''\n",
    "\n",
    "# attribute \"anticodon\" is uniquely in RefSeq but still in the GFF output\n",
    "# --> attributes \n",
    "\n",
    "mane_attr = chessApi.execute_query(single_source_attr_names_MANE)\n",
    "gencode_attr = chessApi.execute_query(single_source_attr_names_GENCODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ccdsid',),\n",
       " ('gene_id',),\n",
       " ('gene_name',),\n",
       " ('gene_type',),\n",
       " ('havana_gene',),\n",
       " ('havana_transcript',),\n",
       " ('hgnc_id',),\n",
       " ('level',),\n",
       " ('protein_id',),\n",
       " ('tag',),\n",
       " ('transcript_id',),\n",
       " ('transcript_name',),\n",
       " ('transcript_support_level',),\n",
       " ('transcript_type',),\n",
       " ('ont',)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gencode_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Testing Functions\n",
    "####################\n",
    "\n",
    "# Check if the right data sources are in the file\n",
    "def parse_gtf_and_check_data_sources(file_path, data_sources):\n",
    "    sources_found = set()\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('#'):\n",
    "                continue  # Skip comment lines\n",
    "            columns = line.strip().split('\\t')\n",
    "            source_name = columns[1]\n",
    "            sources_found.add(source_name)\n",
    "\n",
    "    # Check if all expected sources are found and there are no extra sources\n",
    "    all_sources_present = all(source in sources_found for source in data_sources)\n",
    "    no_extra_sources = all(source in data_sources for source in sources_found)\n",
    "    return all_sources_present and no_extra_sources, sources_found\n",
    "\n",
    "# Check if attributes distinct to a source are in the file \n",
    "def find_missing_attributes_keys(source1_attr, source2_attr, file_path):\n",
    "    # Convert attribute tuples to sets for easy comparison\n",
    "    source1_set = set(attr[0] for attr in source1_attr)\n",
    "    source2_set = set(attr[0] for attr in source2_attr)\n",
    "\n",
    "    # Find attributes unique to GENCODE and MANE\n",
    "    unique_to_source1 = source1_set - source2_set\n",
    "    unique_to_source2 = source2_set - source1_set\n",
    "\n",
    "    missing_attributes = set()\n",
    "\n",
    "    # Parse the GTF file and check for missing attributes\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('#'):\n",
    "                continue  # Skip comment lines\n",
    "            columns = line.strip().split('\\t')\n",
    "            attributes = columns[-1].split(';')\n",
    "\n",
    "            for attribute in attributes:\n",
    "                key_value = attribute.split(' ')[0]\n",
    "                if key_value not in source1_set and key_value not in source2_set:\n",
    "                    missing_attributes.add(key_value)\n",
    "\n",
    "    \n",
    "    return unique_to_source1, unique_to_source2, missing_attributes\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'ccdsid',\n",
       "  'havana_gene',\n",
       "  'havana_transcript',\n",
       "  'hgnc_id',\n",
       "  'level',\n",
       "  'ont',\n",
       "  'transcript_support_level'},\n",
       " {'CDS_db_xref', 'db_xref'},\n",
       " {''})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################\n",
    "# Calling Tests\n",
    "####################\n",
    "\n",
    "####################\n",
    "# CREATING THE GTF FILE\n",
    "####################\n",
    "# data_sources = ['GENCODE','MANE']\n",
    "# keys = []\n",
    "# values = []\n",
    "# to_gtf_with_inputs(chessApi,data_sources,keys,values,\"RefSeq\",\"gtf\",\"test1\")\n",
    "\n",
    "\n",
    "####################\n",
    "# CHECKING THE OUTPUT\n",
    "####################\n",
    "correct_sources = ['MANE','GENCODE']\n",
    "parse_gtf_and_check_data_sources(\"test1.gtf\",correct_sources)\n",
    "\n",
    "# Checking if all unique attribute keys of GENCODE and MANE are in the output\n",
    "find_missing_attributes_keys(gencode_attr,mane_attr,\"test1.gtf\")\n",
    "\n",
    "# more tests...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Query (for reference; without attribute selection in it)\n",
    "\n",
    "\n",
    "query = '''SELECT na.*, t.sequenceID, t.start, t.end, t.strand, tx.score, t.exons \n",
    "FROM (\n",
    "    SELECT *\n",
    "    FROM (\n",
    "        SELECT a.*, s.name AS source_name,\n",
    "            ROW_NUMBER() OVER(PARTITION BY a.tid, a.name ORDER BY a.tid, a.name,\n",
    "                CASE\n",
    "                    WHEN s.name = 'CHESS.3.0' THEN 0\n",
    "                    WHEN s.name = 'RefSeq' THEN 1\n",
    "                    WHEN s.name = 'MANE' THEN 2\n",
    "                    ELSE 3  -- Place other sources at the end\n",
    "                END) AS rn\n",
    "        FROM Attributes a\n",
    "        JOIN Sources s ON a.sourceID = s.sourceID\n",
    "    ) AS ranked\n",
    "    WHERE rn = 1 AND (source_name = 'CHESS.3.0' OR source_name = 'RefSeq' OR source_name = 'MANE')\n",
    ") na \n",
    "JOIN TxDBXREF tx ON na.tid = tx.tid AND na.sourceID = tx.sourceID AND na.transcript_id = tx.transcript_id \n",
    "JOIN Transcripts t ON tx.tid = t.tid'''\n",
    "\n",
    "select_res = chessApi.execute_query(a)\n",
    "select_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting the database\n",
    "# Remove all datapoints that are not in CHESS.3.0, RefSeq or MANE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "############  EXTRACT GTF WITH INPUTS    ############\n",
    "#####################################################\n",
    "from collections import defaultdict\n",
    "\n",
    "\"\"\"\n",
    "  @brief: Returns a GTF/GFF file from the database using the given inputs\n",
    "\n",
    "  @param: self: CHESS_DB_API object\n",
    "  @param: data_sources: list of data sources to extract from the database (in order of priority)\n",
    "  @param: keys: list of attribute keys/names\n",
    "  @param: values: list of attribute values\n",
    "  @param: nomenclature: nomenclature of the sequenceID\n",
    "  @param: output_file_type: output file type (\"gff\" or \"gtf\")\n",
    "  @param: output_file_name: output file name\n",
    "  @return: GTF/GFF file that meets input criteria\n",
    "\"\"\"\n",
    "def to_gtf_with_inputs(self,data_sources:list,keys:list, values:list, nomenclature:str, output_file_type: str, output_file_name:str):\n",
    "    \n",
    "    ####################\n",
    "    # SQL Query\n",
    "    ####################\n",
    "\n",
    "    # Create SQL clause for data sources\n",
    "    sources_condition = \" OR \".join([f\"source_name = '{source}'\" for source in data_sources])\n",
    "    \n",
    "    # Create SQL clause for attributes\n",
    "    where_clause = \"\"\n",
    "    if keys and values:\n",
    "        conditions = []\n",
    "        for key, value in zip(keys, values):\n",
    "            conditions.append(f\"(name = '{key}' AND value = '{value}')\")\n",
    "        where_clause = \"WHERE \" + \" OR \".join(conditions)\n",
    "\n",
    "    # SQL query\n",
    "    query = f'''SELECT na.*, t.sequenceID, tx.start, tx.end, t.strand, tx.score, t.exons, tx.cds, t.assemblyName\n",
    "    FROM (\n",
    "        SELECT *\n",
    "        FROM (\n",
    "            SELECT a.*, s.name AS source_name,\n",
    "                ROW_NUMBER() OVER(PARTITION BY a.tid, a.name ORDER BY a.tid, a.name,\n",
    "                    CASE {''.join([f\"WHEN s.name = '{source}' THEN {index} \" for index, source in enumerate(data_sources)])}\n",
    "                    ELSE {len(data_sources)}  -- Place other sources at the end\n",
    "                END) AS rn\n",
    "            FROM Attributes a\n",
    "            JOIN Sources s ON a.sourceID = s.sourceID\n",
    "        ) AS ranked\n",
    "        WHERE rn = 1 AND ({sources_condition})\n",
    "    ) na \n",
    "    JOIN TxDBXREF tx ON na.tid = tx.tid AND na.sourceID = tx.sourceID AND na.transcript_id = tx.transcript_id \n",
    "    JOIN Transcripts t ON tx.tid = t.tid\n",
    "    {where_clause}\n",
    "    '''\n",
    "\n",
    "    # Execute Query\n",
    "    select_res = self.execute_query(query)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Find sequenceId for a given nomenclature\n",
    "    # Execute the SQL query\n",
    "    query = \"SELECT assemblyName, sequenceID, nomenclature, alternativeID FROM SequenceIDMap\"\n",
    "    sid = chessApi.execute_query(query)\n",
    "\n",
    "    # Create a dictionary mapping assemblyName, sequenceId, and nomenclature to alternativeID\n",
    "    sequence_id_map = {}\n",
    "    for row in sid:\n",
    "        key = (row[0], row[1], row[2])  # Use assemblyName, sequenceID, and nomenclature as the key\n",
    "        value = row[3]  # alternativeID as the value\n",
    "        if key not in sequence_id_map:\n",
    "            sequence_id_map[key] = []\n",
    "        sequence_id_map[key].append(value)\n",
    "\n",
    "\n",
    "    ####################\n",
    "    # Create GFF/GTF file\n",
    "    ####################\n",
    "\n",
    "    # dictionary mapping transcript id to the row in the SQL query output\n",
    "    transcript_data = defaultdict(list) # automatically initializes a list for each key\n",
    "    for row in select_res:\n",
    "        transcript_id = row[0]  # Assuming transcript_id is in the first position\n",
    "        transcript_data[transcript_id].append(row)\n",
    "\n",
    "    # Writing the GTF/GFF file\n",
    "    outfname = f\"{output_file_name}.{output_file_type}\"\n",
    "\n",
    "    with open(outfname, \"w\") as outFP:\n",
    "        for transcript_id, rows in transcript_data.items():\n",
    "            output_str = \"\"\n",
    "            # Construct transcript line\n",
    "            attribute_list = [(row[3], row[4].replace(\"\\t\", \"\")) for row in rows if row[3] not in [\"transcript_id\", \"transcriptId\"]]\n",
    "\n",
    "            if (output_file_type==\"gtf\"):\n",
    "                attributes = \"; \".join(f\"{attr[0]} \\\"{attr[1]}\\\"\" for attr in attribute_list)\n",
    "\n",
    "            if(output_file_type==\"gff\"):\n",
    "                attributes = \";\".join(f\"{attr[0]}={attr[1]}\" for attr in attribute_list)\n",
    "\n",
    "            # print(attributes + \"\\n\")\n",
    "            strand = \"+\" if rows[0][10] == 1 else \"-\"\n",
    "\n",
    "            # find sequenceId (assemblyId, sequenceId, nomencalture --> alternativeID)\n",
    "            sequence_id = sequence_id_map[(rows[0][14], rows[0][7], nomenclature)][0]\n",
    "\n",
    "            # main line for constucting the gtf/gff file\n",
    "            if (output_file_type==\"gtf\"):\n",
    "                output_str = f\"{sequence_id}\\t{rows[0][5]}\\ttranscript\\t{rows[0][8]}\\t{rows[0][9]}\\t.\\t{strand}\\t.\\ttranscript_id \\\"{rows[0][2]}\\\"; {attributes}\\n\"\n",
    "\n",
    "            if(output_file_type==\"gff\"):\n",
    "                output_str = f\"{sequence_id}\\t{rows[0][5]}\\ttranscript\\t{rows[0][8]}\\t{rows[0][9]}\\t.\\t{strand}\\t.\\ttranscript_id={rows[0][2]};{attributes}\\n\"\n",
    "\n",
    "            outFP.write(output_str)\n",
    "\n",
    "            # construct exon lines\n",
    "            output_str = \"\"\n",
    "\n",
    "            # print exons\n",
    "            if (rows[0][12] != None):\n",
    "                for exon in rows[0][12].split(\",\"):\n",
    "                    exon_start, exon_end = [str(int(v)) for v in exon.split(\"-\")]\n",
    "                    output_str += sequence_id+\"\\t\"+str(rows[0][5])+\"\\texon\\t\"+exon_start+\"\\t\"+exon_end+\"\\t.\\t\"+strand+\"\\t.\\ttranscript_id \\\"\"+str(rows[0][2])+\"\\\";\\n\"\n",
    "                \n",
    "            # print CDS\n",
    "            if (rows[0][13] != None):\n",
    "                for cds in rows[0][13].split(\",\"):\n",
    "                    cds_start, cds_end = [str(int(v)) for v in cds.split(\"-\")]\n",
    "                    output_str += sequence_id+\"\\t\"+str(rows[0][5])+\"\\tCDS\\t\"+cds_start+\"\\t\"+cds_end+\"\\t.\\t\"+strand+\"\\t.\\ttranscript_id \\\"\"+str(rows[0][2])+\"\\\";\\n\"\n",
    "\n",
    "            outFP.write(output_str)\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####################################################\n",
    "############  EXTRACT GTF WITH INPUTS    ############\n",
    "#####################################################\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
